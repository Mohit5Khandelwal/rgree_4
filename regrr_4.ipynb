{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression, short for Least Absolute Shrinkage and Selection Operator Regression, is a linear regression technique that, like Ridge Regression, adds a regularization term to the linear regression cost function. However, Lasso Regression uses the L1 regularization term, which is the absolute sum of the regression coefficients multiplied by a tuning parameter (λ). This L1 regularization encourages sparsity in the coefficient values, effectively setting some coefficients to exactly zero. This makes Lasso Regression useful for feature selection, as it can automatically identify and select the most relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of using Lasso Regression in feature selection is its ability to automatically identify and select a subset of the most important features by setting the coefficients of irrelevant features to zero. This results in a simpler and more interpretable model that can potentially perform better on new, unseen data by reducing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the coefficients in a Lasso Regression model is similar to interpreting coefficients in ordinary linear regression. A positive coefficient means that an increase in the corresponding independent variable is associated with an increase in the dependent variable, and vice versa for negative coefficients. However, due to the L1 regularization, some coefficients may be exactly zero, indicating that the associated features have been excluded from the model. The size of the non-zero coefficients still reflects the strength of the relationship between the independent variables and the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lasso Regression, the primary tuning parameter is λ (lambda), which controls the strength of the L1 regularization. A larger λ will result in more coefficients being pushed to zero, increasing sparsity, while a smaller λ will allow more coefficients to remain non-zero. The tuning parameter can be adjusted to balance between model simplicity and accuracy. Cross-validation techniques can be used to find the optimal value of λ that provides the best model performance on a validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression is inherently a linear regression technique and is not designed for non-linear regression problems. It can handle non-linear relationships between variables to some extent, but for highly non-linear problems, other regression techniques like polynomial regression or non-linear models (e.g., decision trees, support vector machines) are more suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between Ridge Regression and Lasso Regression lies in the type of regularization they apply:\n",
    "\n",
    "Ridge Regression uses L2 regularization, which penalizes the sum of the squares of the coefficients.\n",
    "Lasso Regression uses L1 regularization, which penalizes the absolute sum of the coefficients.\n",
    "The key practical difference is that Lasso Regression can lead to sparsity in the coefficients by setting some of them to exactly zero, effectively performing feature selection, while Ridge Regression tends to shrink the coefficients towards but not exactly to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can handle multicollinearity in the input features. Similar to Ridge Regression, Lasso can reduce the impact of multicollinearity by shrinking the coefficients, and in some cases, it can even set some of the coefficients to zero, effectively choosing one variable from a correlated group. This helps in feature selection and simplifies the model, making it more robust in the presence of multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the optimal value of the regularization parameter (λ) in Lasso Regression, you can use cross-validation techniques. The most common method is k-fold cross-validation, where you split your dataset into k subsets (folds), train the Lasso Regression model on k-1 of these folds, and evaluate its performance on the remaining fold. Repeat this process for different values of λ, and choose the one that results in the best performance (e.g., lowest mean squared error or highest R-squared) on the validation folds. This will help you find the λ that balances model complexity and predictive accuracy."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
